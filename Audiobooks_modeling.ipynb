{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audiobooks_modeling",
      "provenance": [],
      "mount_file_id": "1Uf-cXsTXsh9n5xOM2lWxbIW18a-j28FR",
      "authorship_tag": "ABX9TyMjq35GHeMrbXnXtdJKNzsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacquesjh/Audiobook/blob/main/Audiobooks_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Qs3icnltSS"
      },
      "source": [
        "#Começamos verificando o diretório em que estamos trabalhando, neste caso, queremos estar trabalhando na mesma pasta em que pré processamos os dados, por simplicidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTWaY-bnS-nx",
        "outputId": "fcb29fba-7dac-4d36-9674-1af3a27ca20e"
      },
      "source": [
        "%cd /content/drive/MyDrive/Machine Learning/Audiobook"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Machine Learning/Audiobook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RYZNgrel8j1"
      },
      "source": [
        "#Com isso, podemos, então importar as bibliotecas relevantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-iI4LM8S_xD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJFbGMrImCJY"
      },
      "source": [
        "#Agora devemos carregar os dados pré processados da pasta que foram salvos (a mesma que já estamos) e armazena-los no nosso código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1S7qUecUhoB"
      },
      "source": [
        "##Sabemos que os inputs devem ser do tipo float, e targets são do tipo int (ou 0 ou 1)\n",
        "##portanto, usamos a função .astype para garantir que sejam deste tipo, mesmo que eles talvez já sejam\n",
        "npz = np.load(\"Audiobooks_train_data.npz\")\n",
        "\n",
        "train_inputs = npz['inputs'].astype(np.float)\n",
        "train_targets = npz['targets'].astype(np.int)\n",
        "\n",
        "##Agora vamo carregar os dados de validation\n",
        "npz = np.load(\"Audiobooks_validation_data.npz\")\n",
        "\n",
        "validation_inputs = npz['inputs'].astype(np.float)\n",
        "validation_targets = npz['targets'].astype(np.int)\n",
        "\n",
        "##Então carregamos os dados de test\n",
        "npz = np.load(\"Audiobooks_test_data.npz\")\n",
        "\n",
        "test_inputs = npz['inputs'].astype(np.float)\n",
        "test_targets = npz['targets'].astype(np.int)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YluEuRX5nagN"
      },
      "source": [
        "##Agora iremos finalmente criar o nosso modelo de rede neural para aprender nos datasets criados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vKxNISQnjQp"
      },
      "source": [
        "##Nós sabemos que os inputs possuem 10 dimensões (parâmetros), assim, a primeira camada da nossa rede deve ter 10 nodos, um para cada dimnesâo.\n",
        "##Também, sabemos que a saída esperada da nossa rede tem apenas duas possibilidades, 0 ou 1, então a ultima camada deve possuir 2 nodos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFK7g_wUnhzo"
      },
      "source": [
        "##Definindo os hyperparâmetros da nossa rede\n",
        "inputs_size = 10\n",
        "targets_size = 2\n",
        "hidden_layer_size = 64"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXV5JerlpCDK"
      },
      "source": [
        "##Criando a nossa rede neural\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"),\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(32, activation = \"relu\"),\n",
        "                             tf.keras.layers.Dense(targets_size, activation = \"softmax\")\n",
        "                            ])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwNow5ZmsVT7"
      },
      "source": [
        "## Agora nos devemos treinar nosso modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH35hc4vraI0",
        "outputId": "ae8136ad-8a7d-4f0c-c527-c11446e96d98"
      },
      "source": [
        "##Agora precisamos definir como iremos treinar nosso modelo, ou seja, o tamanho de bach e o numero de epochs\n",
        "batch_size = 64\n",
        "max_epochs = 100\n",
        "\n",
        "##Podemos adicionar um mecanismo de early stopping, para que o treinamento pare quando o val_loss começar a aumentar, ao inves de diminuir\n",
        "##O parâmetro patience é quantas vezes o mecanismo tolera o val_loss diminuir antes de parar o treinamento\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 4)\n",
        "\n",
        "\n",
        "model.fit(train_inputs,\n",
        "          train_targets,\n",
        "          batch_size = batch_size,\n",
        "          epochs = max_epochs,\n",
        "          callbacks = early_stopping,\n",
        "          validation_data = (validation_inputs, validation_targets),\n",
        "          verbose = 2\n",
        "          )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "56/56 - 0s - loss: 0.5300 - accuracy: 0.7287 - val_loss: 0.4473 - val_accuracy: 0.7718\n",
            "Epoch 2/100\n",
            "56/56 - 0s - loss: 0.4183 - accuracy: 0.7815 - val_loss: 0.3916 - val_accuracy: 0.7987\n",
            "Epoch 3/100\n",
            "56/56 - 0s - loss: 0.3955 - accuracy: 0.7969 - val_loss: 0.3770 - val_accuracy: 0.8076\n",
            "Epoch 4/100\n",
            "56/56 - 0s - loss: 0.3787 - accuracy: 0.8044 - val_loss: 0.3699 - val_accuracy: 0.8098\n",
            "Epoch 5/100\n",
            "56/56 - 0s - loss: 0.3677 - accuracy: 0.8047 - val_loss: 0.3639 - val_accuracy: 0.8076\n",
            "Epoch 6/100\n",
            "56/56 - 0s - loss: 0.3631 - accuracy: 0.8122 - val_loss: 0.3697 - val_accuracy: 0.7942\n",
            "Epoch 7/100\n",
            "56/56 - 0s - loss: 0.3618 - accuracy: 0.8066 - val_loss: 0.3675 - val_accuracy: 0.8121\n",
            "Epoch 8/100\n",
            "56/56 - 0s - loss: 0.3599 - accuracy: 0.8164 - val_loss: 0.3610 - val_accuracy: 0.7987\n",
            "Epoch 9/100\n",
            "56/56 - 0s - loss: 0.3566 - accuracy: 0.8078 - val_loss: 0.3565 - val_accuracy: 0.8121\n",
            "Epoch 10/100\n",
            "56/56 - 0s - loss: 0.3543 - accuracy: 0.8142 - val_loss: 0.3493 - val_accuracy: 0.8143\n",
            "Epoch 11/100\n",
            "56/56 - 0s - loss: 0.3505 - accuracy: 0.8178 - val_loss: 0.3579 - val_accuracy: 0.8166\n",
            "Epoch 12/100\n",
            "56/56 - 0s - loss: 0.3509 - accuracy: 0.8114 - val_loss: 0.3516 - val_accuracy: 0.8255\n",
            "Epoch 13/100\n",
            "56/56 - 0s - loss: 0.3466 - accuracy: 0.8206 - val_loss: 0.3502 - val_accuracy: 0.8031\n",
            "Epoch 14/100\n",
            "56/56 - 0s - loss: 0.3486 - accuracy: 0.8136 - val_loss: 0.3492 - val_accuracy: 0.8031\n",
            "Epoch 15/100\n",
            "56/56 - 0s - loss: 0.3415 - accuracy: 0.8189 - val_loss: 0.3444 - val_accuracy: 0.8076\n",
            "Epoch 16/100\n",
            "56/56 - 0s - loss: 0.3413 - accuracy: 0.8153 - val_loss: 0.3518 - val_accuracy: 0.8166\n",
            "Epoch 17/100\n",
            "56/56 - 0s - loss: 0.3383 - accuracy: 0.8248 - val_loss: 0.3470 - val_accuracy: 0.8031\n",
            "Epoch 18/100\n",
            "56/56 - 0s - loss: 0.3399 - accuracy: 0.8217 - val_loss: 0.3496 - val_accuracy: 0.8188\n",
            "Epoch 19/100\n",
            "56/56 - 0s - loss: 0.3389 - accuracy: 0.8206 - val_loss: 0.3569 - val_accuracy: 0.7919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa6e0cd668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O9lNMYUE6UD"
      },
      "source": [
        "#Agora, com o nosso modelo treinado nos datasets de train e validation, resto apenas testá-lo sobre um novo dataset: test_data. É como se estivessemos utilizando o modelo na prática"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVpI62rjsdw5",
        "outputId": "965704a7-f6de-4f12-ef5c-925adf01143b"
      },
      "source": [
        "##Testando o modelo\n",
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m4VZrQoFTI4",
        "outputId": "87a7fa5d-774d-4783-9630-7d3df1009afe"
      },
      "source": [
        "print(\"Agora temos um modelo funcional para previsão de conversão de clientes.\")\n",
        "print(\"\\nA precisão do modelo é de: {0:.2f}%\".format(test_accuracy*100.))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agora temos um modelo funcional para previsão de conversão de clientes.\n",
            "\n",
            "A precisão do modelo é de: 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afsc55Rg7OVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
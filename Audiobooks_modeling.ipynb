{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audiobooks_modeling",
      "provenance": [],
      "mount_file_id": "1Uf-cXsTXsh9n5xOM2lWxbIW18a-j28FR",
      "authorship_tag": "ABX9TyNb2+MIi+67EnC/ok3wxwJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacquesjh/Audiobook/blob/main/Audiobooks_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Qs3icnltSS"
      },
      "source": [
        "#Começamos verificando o diretório em que estamos trabalhando, neste caso, queremos estar trabalhando na mesma pasta em que pré processamos os dados, por simplicidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTWaY-bnS-nx",
        "outputId": "6506154f-b424-4e7b-86b7-1e5bd4210cac"
      },
      "source": [
        "%cd /content/drive/MyDrive/Machine Learning/Audiobook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Machine Learning/Audiobook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RYZNgrel8j1"
      },
      "source": [
        "#Com isso, podemos, então importar as bibliotecas relevantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-iI4LM8S_xD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJFbGMrImCJY"
      },
      "source": [
        "#Agora devemos carregar os dados pré processados da pasta que foram salvos (a mesma que já estamos) e armazena-los no nosso código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1S7qUecUhoB"
      },
      "source": [
        "##Sabemos que os inputs devem ser do tipo float, e targets são do tipo int (ou 0 ou 1)\n",
        "##portanto, usamos a função .astype para garantir que sejam deste tipo, mesmo que eles talvez já sejam\n",
        "npz = np.load(\"Audiobooks_train_data.npz\")\n",
        "\n",
        "train_inputs = npz['inputs'].astype(np.float)\n",
        "train_targets = npz['targets'].astype(np.int)\n",
        "\n",
        "##Agora vamo carregar os dados de validation\n",
        "npz = np.load(\"Audiobooks_validation_data.npz\")\n",
        "\n",
        "validation_inputs = npz['inputs'].astype(np.float)\n",
        "validation_targets = npz['targets'].astype(np.int)\n",
        "\n",
        "##Então carregamos os dados de test\n",
        "npz = np.load(\"Audiobooks_test_data.npz\")\n",
        "\n",
        "test_inputs = npz['inputs'].astype(np.float)\n",
        "test_targets = npz['targets'].astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YluEuRX5nagN"
      },
      "source": [
        "##Agora iremos finalmente criar o nosso modelo de rede neural para aprender nos datasets criados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vKxNISQnjQp"
      },
      "source": [
        "##Nós sabemos que os inputs possuem 10 dimensões (parâmetros), assim, a primeira camada da nossa rede deve ter 10 nodos, um para cada dimnesâo.\n",
        "##Também, sabemos que a saída esperada da nossa rede tem apenas duas possibilidades, 0 ou 1, então a ultima camada deve possuir 2 nodos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFK7g_wUnhzo"
      },
      "source": [
        "##Definindo os hyperparâmetros da nossa rede\n",
        "inputs_size = 10\n",
        "targets_size = 2\n",
        "hidden_layer_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXV5JerlpCDK"
      },
      "source": [
        "##Criando a nossa rede neural\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"),\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation = \"relu\"),\n",
        "                             tf.keras.layers.Dense(targets_size, activation = \"softmax\")\n",
        "                            ])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwNow5ZmsVT7"
      },
      "source": [
        "## Agora nos devemos treinar nosso modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH35hc4vraI0",
        "outputId": "5ade4f95-292d-4510-c71d-3c5eef4eb1c9"
      },
      "source": [
        "##Agora precisamos definir como iremos treinar nosso modelo, ou seja, o tamanho de bach e o numero de epochs\n",
        "batch_size = 100\n",
        "max_epochs = 100\n",
        "\n",
        "##Podemos adicionar um mecanismo de early stopping, para que o treinamento pare quando o val_loss começar a aumentar, ao inves de diminuir\n",
        "##O parâmetro patience é quantas vezes o mecanismo tolera o val_loss diminuir antes de parar o treinamento\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)\n",
        "\n",
        "\n",
        "model.fit(train_inputs,\n",
        "          train_targets,\n",
        "          batch_size = batch_size,\n",
        "          epochs = max_epochs,\n",
        "          callbacks = [early_stopping],\n",
        "          validation_data = (validation_inputs, validation_targets),\n",
        "          verbose = 2\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 - 0s - loss: 0.5877 - accuracy: 0.6865 - val_loss: 0.5258 - val_accuracy: 0.7494\n",
            "Epoch 2/100\n",
            "36/36 - 0s - loss: 0.4716 - accuracy: 0.7714 - val_loss: 0.4487 - val_accuracy: 0.7852\n",
            "Epoch 3/100\n",
            "36/36 - 0s - loss: 0.4140 - accuracy: 0.7798 - val_loss: 0.4176 - val_accuracy: 0.7740\n",
            "Epoch 4/100\n",
            "36/36 - 0s - loss: 0.3858 - accuracy: 0.7913 - val_loss: 0.3973 - val_accuracy: 0.7897\n",
            "Epoch 5/100\n",
            "36/36 - 0s - loss: 0.3708 - accuracy: 0.8011 - val_loss: 0.3889 - val_accuracy: 0.7875\n",
            "Epoch 6/100\n",
            "36/36 - 0s - loss: 0.3578 - accuracy: 0.8058 - val_loss: 0.3816 - val_accuracy: 0.7718\n",
            "Epoch 7/100\n",
            "36/36 - 0s - loss: 0.3537 - accuracy: 0.8053 - val_loss: 0.3744 - val_accuracy: 0.7875\n",
            "Epoch 8/100\n",
            "36/36 - 0s - loss: 0.3456 - accuracy: 0.8117 - val_loss: 0.3719 - val_accuracy: 0.7785\n",
            "Epoch 9/100\n",
            "36/36 - 0s - loss: 0.3404 - accuracy: 0.8189 - val_loss: 0.3675 - val_accuracy: 0.8009\n",
            "Epoch 10/100\n",
            "36/36 - 0s - loss: 0.3365 - accuracy: 0.8156 - val_loss: 0.3630 - val_accuracy: 0.8009\n",
            "Epoch 11/100\n",
            "36/36 - 0s - loss: 0.3333 - accuracy: 0.8201 - val_loss: 0.3724 - val_accuracy: 0.8054\n",
            "Epoch 12/100\n",
            "36/36 - 0s - loss: 0.3308 - accuracy: 0.8231 - val_loss: 0.3582 - val_accuracy: 0.7852\n",
            "Epoch 13/100\n",
            "36/36 - 0s - loss: 0.3291 - accuracy: 0.8153 - val_loss: 0.3643 - val_accuracy: 0.8098\n",
            "Epoch 14/100\n",
            "36/36 - 0s - loss: 0.3308 - accuracy: 0.8178 - val_loss: 0.3674 - val_accuracy: 0.8054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd81e40e7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O9lNMYUE6UD"
      },
      "source": [
        "#Agora, com o nosso modelo treinado nos datasets de train e validation, resto apenas testá-lo sobre um novo dataset: test_data. É como se estivessemos utilizando o modelo na prática"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVpI62rjsdw5",
        "outputId": "9b1e4af0-861e-4d4a-cbd5-f30068c0ab07"
      },
      "source": [
        "##Testando o modelo\n",
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m4VZrQoFTI4",
        "outputId": "5f7236e6-d07a-47a2-c276-31d0a8e19015"
      },
      "source": [
        "print(\"Agora temos um modelo funcional para previsão de conversão de clientes.\")\n",
        "print(\"\\nA precisão do modelo é de: {0:.2f}%\".format(test_accuracy*100.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agora temos um modelo funcional para previsão de conversão de clientes\n",
            "\n",
            "A precisão do modelo é de: 83.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KcloKrcGapT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}